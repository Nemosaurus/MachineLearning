{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "class AdalineSGD(object):\n",
    " \"\"\"ADAptive LInear NEuron classifier.\n",
    " Parameters\n",
    " ------------\n",
    " eta : float\n",
    " Learning rate (between 0.0 and 1.0)\n",
    " n_iter : int\n",
    " Passes over the training dataset.\n",
    " Attributes\n",
    " -----------\n",
    " w_ : 1d-array\n",
    " Weights after fitting.\n",
    " errors_ : list\n",
    " Number of misclassifications in every epoch.\n",
    " shuffle : bool (default: True)\n",
    " Shuffles training data every epoch \n",
    " if True to prevent cycles.\n",
    " random_state : int (default: None)\n",
    " Set random state for shuffling \n",
    " and initializing the weights.\n",
    " \n",
    " \"\"\"\n",
    " def __init__(self, eta=0.01, n_iter=10, \n",
    " shuffle=True, random_state=None):\n",
    " self.eta = eta\n",
    " self.n_iter = n_iter\n",
    " self.w_initialized = False\n",
    " self.shuffle = shuffle\n",
    "     if random_state:\n",
    " seed(random_state)\n",
    " \n",
    " def fit(self, X, y):\n",
    " \"\"\" Fit training data.\n",
    " Parameters\n",
    " ----------\n",
    " X : {array-like}, shape = [n_samples, n_features]\n",
    " Training vectors, where n_samples \n",
    " is the number of samples and\n",
    " n_features is the number of features.\n",
    " y : array-like, shape = [n_samples]\n",
    " Target values.\n",
    " Returns\n",
    " -------\n",
    " self : object\n",
    " \"\"\"\n",
    " self._initialize_weights(X.shape[1])\n",
    " self.cost_ = []\n",
    " for i in range(self.n_iter):\n",
    " if self.shuffle:\n",
    " X, y = self._shuffle(X, y)\n",
    " cost = []\n",
    " for xi, target in zip(X, y):\n",
    " cost.append(self._update_weights(xi, target))\n",
    " avg_cost = sum(cost)/len(y)\n",
    " self.cost_.append(avg_cost)\n",
    " return self\n",
    " def partial_fit(self, X, y):\n",
    " \"\"\"Fit training data without reinitializing the weights\"\"\"\n",
    " if not self.w_initialized:\n",
    " self._initialize_weights(X.shape[1])\n",
    " if y.ravel().shape[0] > 1:\n",
    " for xi, target in zip(X, y):\n",
    " self._update_weights(xi, target)\n",
    " else:\n",
    " self._update_weights(X, y)\n",
    " return self\n",
    " def _shuffle(self, X, y):\n",
    "        \n",
    "         \"\"\"Shuffle training data\"\"\"\n",
    " r = np.random.permutation(len(y))\n",
    " return X[r], y[r]\n",
    " \n",
    " def _initialize_weights(self, m):\n",
    " \"\"\"Initialize weights to zeros\"\"\"\n",
    " self.w_ = np.zeros(1 + m)\n",
    " self.w_initialized = True\n",
    " \n",
    " def _update_weights(self, xi, target):\n",
    " \"\"\"Apply Adaline learning rule to update the weights\"\"\"\n",
    " output = self.net_input(xi)\n",
    " error = (target - output)\n",
    " self.w_[1:] += self.eta * xi.dot(error)\n",
    " self.w_[0] += self.eta * error\n",
    " cost = 0.5 * error**2\n",
    " return cost\n",
    " \n",
    " def net_input(self, X):\n",
    " \"\"\"Calculate net input\"\"\"\n",
    " return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    " def activation(self, X):\n",
    " \"\"\"Compute linear activation\"\"\"\n",
    " return self.net_input(X)\n",
    " def predict(self, X):\n",
    " \"\"\"Return class label after unit step\"\"\"\n",
    " return np.where(self.activation(X) >= 0.0, 1, -1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
